# Лабораторная работа №1. Предобработка данных

## 1. Выбор набора данных

Для выполнения лабораторной работы был выбран открытый набор данных "Titanic - Machine Learning from Disaster", доступный на платформе Kaggle.

**Описание**:

* Набор содержит информацию о пассажирах Титаника.
* Целевая переменная — **Survived** (выжил ли пассажир).
* Признаки: имя, возраст, класс каюты, цена билета и т.д.

**Ссылка для загрузки**:

https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv

Анализ данных приведен в файле [notebooks/eda_and_preprocessing.ipynb](notebooks/eda_and_preprocessing.ipynb)

## 2. Постановка задачи машинного обучения

**Задача**:

Предсказать, выжил ли пассажир Титаника (`Survived = 1`) или нет (`Survived = 0`) на основе его характеристик.

**Тип задачи**:

Бинарная классификация

**Метрики качества модели**:

* Accuracy
* Precision
* Recall
* F1-score
* ROC AUC

## 3. Выбор системы хранения данных

У нас в качестве данных небольшая CSV-таблица, поэтому подойдет либо обычный CSV-файл, либо база данных SQLite.

Сохранение предобработанных данных приведено в файле [scripts/load_to_sqlite.py](scripts/load_to_sqlite.py)

## 4. Реализация предобработки данных

Используем Pandas для простоты, но также можно использовать Apache Spark для работы с большими данными.

Предобработка данных приведена в файле [scripts/preprocess.py](scripts/preprocess.py)

## 5. Автоматизация с использованием Apache Airflow

Airflow используется для оркестрации ETL-процессов.

### Архитектура DAG

1. Загрузка новых данных
2. Предобработка
3. Сохранение в SQLite

## Выводы

В ходе данной лабораторной работы:

* Был выбран и проанализирован датасет Titanic.
* Выполнена полная предобработка данных: обработка пропусков, кодирование категориальных признаков, удаление нерелевантных столбцов.
* Данные сохранены и готовы к обучению модели.
* Создан автоматизированный пайплайн с использованием Airflow.
